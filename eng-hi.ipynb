{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "510739dd-57b8-4813-bd76-523f4f403b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.97-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "697153f2-2025-4948-859b-a9e716437562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.8.2-py3-none-any.whl (10 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Using cached tokenizers-0.13.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.10.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (770 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Using cached huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.13)\n",
      "Installing collected packages: tokenizers, regex, filelock, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.8.2 huggingface-hub-0.11.1 regex-2022.10.31 tokenizers-0.13.2 transformers-4.25.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cba0b741-5a2c-4672-b3b9-f4f809884372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Using cached gTTS-2.3.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: click~=8.1.3 in /opt/conda/lib/python3.10/site-packages (from gtts) (8.1.3)\n",
      "Requirement already satisfied: requests~=2.28.0 in /opt/conda/lib/python3.10/site-packages (from gtts) (2.28.1)\n",
      "Requirement already satisfied: six~=1.16.0 in /opt/conda/lib/python3.10/site-packages (from gtts) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->gtts) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->gtts) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->gtts) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->gtts) (1.26.13)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f683e1c9-b926-4da4-b316-9d4077a4cfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch\n",
      "Successfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ea875b-5a25-4b50-b8b3-e669bfe241ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "source = 'en'\n",
    "target = 'hi'\n",
    "model_name = f\"Helsinki-NLP/opus-mt-{source}-{target}\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64ca977a-6034-4231-ae5c-59697a04dc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method PreTrainedTokenizerBase.as_target_tokenizer of PreTrainedTokenizer(name_or_path='Helsinki-NLP/opus-mt-en-hi', vocab_size=61950, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'})>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.as_target_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a95ebfe-41ed-455d-982e-4bd09b0a39c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e5f16f-ae56-4d8c-a3a0-1d4e8d61b27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[   81,   902,     8,     4,  9462,    21,     4, 15099,  6353, 25310,\n",
      "          5588,     4,   902,     8,   287,     4,  9462,    54,  2332,    21,\n",
      "             4, 12121,  1809,   583,     3, 16898,     8,     4,  3610,  6353,\n",
      "         25310,    26,    54,    36,  2332,    54, 13099,    72,     4, 10407,\n",
      "         15099,  6353, 25310,     2,  3026,  2332,    21,     4,  1689, 15635,\n",
      "         27001,     3,   757,  9462,  2332,    50,  1689, 15635,    54,  2696,\n",
      "           145,     4,   410,     7,     4,  4482,     8,     4, 12121,  1809,\n",
      "             3,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[61949,  6327,  7484, 31451,     6,  5096,    11,  5361,    86,    24,\n",
      "          5096,  2838,   161,     5,    25,   280,  5361,  1191,  2758,   342,\n",
      "            11,  1698,    28,     3,  2554,  7484, 31451,     6,  5361,    28,\n",
      "            41,    25,  1513,  1382,  4429, 31451,    12,  4966,   660,   220,\n",
      "            28,     2,   101,   169,    25,  1336,  1382,  5734,  5734,     6,\n",
      "          3044,    29,    51,   273,     3,   141,  5361,    86,    18,  2838,\n",
      "            78,   115,     5,    41,  8240,   331,  6584,     6,  3662,     6,\n",
      "          6474,   772,    11,  4003,   273,     5,     3,     0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'परिवर्तित विशेषता मैट्रिक्स के क्रम में स्तम्भों का क्रम निर्धारित करता है कि कैसे स्तम्भ बदलनेवाले सूची में निर्दिष्ट हैं. मूल विशेषता मैट्रिक्स के स्तम्भ हैं जो कि परिणाम परिवर्तन कक्ष मैट्रिक्स से गिरा दिए गए हैं, जब तक कि फल परिवर्तन अंश अंश के भीतर नहीं हो जाता. उन स्तम्भों को निर्धारित किया गया है जो बदली हुई इकाई के आउटपुट के दाएँ भाग में जोड़ा जाता है.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = 'The order of the columns in the transformed feature matrix follows the order of how the columns are specified in the transformers list. Columns of the original feature matrix that are not specified are dropped from the resulting transformed feature matrix, unless specified in the passthrough keyword. Those columns specified with passthrough are added at the right to the output of the transformers.'\n",
    "batch = tokenizer([sample_text], return_tensors=\"pt\")\n",
    "print(batch)\n",
    "generated_ids = model.generate(**batch)\n",
    "print(generated_ids)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3ac99b7-e63e-4685-ac1d-f759acd43611",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate(lang):\n",
    "    \n",
    "    \n",
    "    '''This project aims to convert languages to Hindi\n",
    "       Choose \"ja\" for Japanese language\n",
    "              \"es\" for Spanish language\n",
    "              \"fr\" for French language\n",
    "              \"ru\" for Russian language\n",
    "              \"zh\" for Taiwanese language\n",
    "              \"ar\" for Arabic language'''\n",
    "    \n",
    "    \n",
    "    if lang == 'ja':\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-{lang}-en\"\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        text = str(input(f'Enter {lang} text: '))\n",
    "        batch = tokenizer([text], return_tensors='pt')\n",
    "        ids = model.generate(**batch)\n",
    "        l_text = tokenizer.batch_decode(ids, skip_special_tokens = True)[0]\n",
    "    elif lang == 'es':\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-{lang}-en\"\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        text = str(input(f'Enter {lang} text: '))\n",
    "        batch = tokenizer([text], return_tensors='pt')\n",
    "        ids = model.generate(**batch)\n",
    "        l_text = tokenizer.batch_decode(ids, skip_special_tokens = True)[0]\n",
    "    elif lang == 'fr':\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-{lang}-en\"\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        text = str(input(f'Enter {lang} text: '))\n",
    "        batch = tokenizer([text], return_tensors='pt')\n",
    "        ids = model.generate(**batch)\n",
    "        l_text = tokenizer.batch_decode(ids, skip_special_tokens = True)[0]\n",
    "    elif lang == 'ru':\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-{lang}-en\"\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        text = str(input(f'Enter {lang} text: '))\n",
    "        batch = tokenizer([text], return_tensors='pt')\n",
    "        ids = model.generate(**batch)\n",
    "        l_text = tokenizer.batch_decode(ids, skip_special_tokens = True)[0]\n",
    "    elif lang == 'zh':\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-{lang}-en\"\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        text = str(input(f'Enter {lang} text: '))\n",
    "        batch = tokenizer([text], return_tensors='pt')\n",
    "        ids = model.generate(**batch)\n",
    "        l_text = tokenizer.batch_decode(ids, skip_special_tokens = True)[0]\n",
    "    elif lang == 'ar':\n",
    "        model_name = f\"Helsinki-NLP/opus-mt-{lang}-en\"\n",
    "        model = MarianMTModel.from_pretrained(model_name)\n",
    "        tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "        text = str(input(f'Enter {lang} text: '))\n",
    "        batch = tokenizer([text], return_tensors='pt')\n",
    "        ids = model.generate(**batch)\n",
    "        l_text = tokenizer.batch_decode(ids, skip_special_tokens = True)[0]\n",
    "    model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "    tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-hi\")\n",
    "    text = l_text\n",
    "    batch = tokenizer([text], return_tensors='pt')\n",
    "    ids = model.generate(**batch)\n",
    "    return tokenizer.batch_decode(ids, skip_special_tokens = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "966316ae-5bb0-4f6f-a26b-a244aacdc2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This project aims to convert languages to Hindi\n",
      "       Choose \"ja\" for Japanese language\n",
      "              \"es\" for Spanish language\n",
      "              \"fr\" for French language\n",
      "              \"ru\" for Russian language\n",
      "              \"zh\" for Taiwanese language\n",
      "              \"ar\" for Arabic language\n"
     ]
    }
   ],
   "source": [
    "print(translate.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94f4d043-ef78-442b-9652-d13add302494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter ar text:  اُخْرُجُوا!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'बाहर जाओ!'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e015693-a777-47b6-8b84-4e20f70004b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
